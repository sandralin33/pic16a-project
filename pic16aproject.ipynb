{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6657868e-f83b-47ac-a105-50a5b41a827b",
   "metadata": {},
   "source": [
    "# Stroke Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544fe674-a3a0-44df-8331-ada6ad04a39e",
   "metadata": {},
   "source": [
    "The goal of this project is to determine which features of an individual’s health data are highly predictive of whether the individual would get a stroke or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b13cf-494e-47b5-b1e6-1d114141b446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import custom class and function\n",
    "from project import DataPreparation, make_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38354884-32d4-4de6-803e-a8c226f939f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076d40e8-b214-4de9-a57c-b5988f6ab56a",
   "metadata": {},
   "source": [
    "We'll be working with the Stroke Prediction dataset from Kaggle, which contains information on patients who had or didn't have a stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504cd3b-97ff-4d8e-9368-34a1057124df",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dbfad4-c3e7-431d-b8b5-afadab94f3a0",
   "metadata": {},
   "source": [
    "First, we imported the dataset. We used a `try-except` block to check if it's a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b4d85e-d506-448b-b953-24f0d2b175ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35325d1d-163b-43c1-8534-791ec2576b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"healthcare-dataset-stroke-data.csv\") # read csv file, save it as a dataframe\n",
    "except csv.Error as error:\n",
    "    print(\"Not a csv file\") # if not a csv file, print error message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb982f-074f-4bbb-963d-18c938395f2b",
   "metadata": {},
   "source": [
    "We created an instance `healthcare` of the class `DataPreparation` to look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1ddde-df25-44c3-acca-6175bc69d5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of the custom class\n",
    "healthcare = DataPreparation(df)\n",
    "healthcare.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c36788-be0e-49fb-96d6-99f97b52c34c",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5aba0-25de-46c8-97ab-16399a73a528",
   "metadata": {},
   "source": [
    "To prep our data for exploratory analysis, we called `__clean_df__()` from `DataPreparation` to convert all the qualitative features to binary values.\n",
    "\n",
    "We converted \"work_type\" to `is_employed`, \"Residence_type\" to `is_Rural`, and \"smoking_status\" to `has_smoked`. We dropped `id`, \"Other\" from `gender`, and all the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a6c72-2144-4864-bfe6-ce2d0df5ff6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean the data by calling the 1st class function\n",
    "healthcare.clean_df()\n",
    "healthcare.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc203b1-c693-4cb2-a5f5-8462c87a67f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870833e-7466-49db-846c-89abbaae027f",
   "metadata": {},
   "source": [
    "Before determining which features are the most relevant to predicting stroke, we made some hypotheses based on the simple graphic comparison between features and their according stroke cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55acff9c-7de1-4a46-b017-b4ae75182f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26587fd8-340c-4a05-b3c6-c574dc1f283c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6a355b-ec18-4c90-8f3e-86332a32d10a",
   "metadata": {},
   "source": [
    "The histograms show the quantitative features (`age`, `avg_glucose_level`, `bmi`) and the number of stroke and non-stroke cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419729c0-cb8c-4cd1-9be1-05c9e3aa29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call make_histogram() function\n",
    "f = [\"age\", \"avg_glucose_level\", \"bmi\"]\n",
    "make_histogram(healthcare.df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17536456-c485-401f-9630-6a328de165a9",
   "metadata": {},
   "source": [
    "1. The histograms of age and stroke and non-stroke cases show that there is a significant trend of people with higher age getting more stroke.\n",
    "2. The second histograms of average glucose level and its stroke and non-stroke cases show that there is a mild trend of people who had stroke having higher average glucose level.\n",
    "3. The third histograms of bmi and its stroke and non-stroke cases didn't show much significance between the feature and number of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f93f2-21f7-4393-8d73-489c041d9e6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exception Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0fa5a6-ce7a-43f6-b668-37509c5134d0",
   "metadata": {},
   "source": [
    "If there are more or less than 3 features, raise `ValueError`, since the histograms are supposed to represent 3 specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef217f-b207-4afe-a4f8-dff106d6dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = [\"age\", \"bmi\"]\n",
    "# make_histogram(healthcare.df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6751ee-0f6e-4549-8907-647730c07460",
   "metadata": {},
   "source": [
    "If the features aren't quantitative, raise `TypeError`. The function will try to detect values over 2, and if there is no value over 2, it will print an error message explaining that the list contains qualitative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04e8e6-b369-4830-8fcf-5dc13b1f7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = [\"age\", \"bmi\", \"gender\"]\n",
    "# make_histogram(healthcare.df, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7df407-5dc0-46a7-aae2-b2679ca36f92",
   "metadata": {},
   "source": [
    "Note: uncomment to test exception handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b473e22-12c7-4a74-94b9-8bf93ddf11f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bargraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58be20d5-b9f5-4d38-9f8e-7ff1103501a9",
   "metadata": {},
   "source": [
    "The bar graphs show the qualitative features (`gender`, `hypertension`, `heart_disease`, `ever_married`, `is_employed`, `is_Rural`, `has_smoked`). The left column shows stroke cases while the right column shows non-stroke cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e289a8-0a87-4f86-8d9e-8838ac572197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data by stroke vs non-stroke cases\n",
    "stroke_true = healthcare.df[\"stroke\"] == 1\n",
    "stroke_false = healthcare.df[\"stroke\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c642c-53d8-4e2f-b904-94b5b30a3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bar graphs\n",
    "fig, axes = plt.subplots(7, 2, figsize = (10, 30))\n",
    "\n",
    "sns.countplot(ax=axes[0,0], data=healthcare.df[stroke_true], x='gender').set(title='stroke') # left column\n",
    "sns.countplot(ax=axes[0,1], data=healthcare.df[stroke_false], x='gender').set(title='no stroke') # right column\n",
    "sns.countplot(ax=axes[1,0], data=healthcare.df[stroke_true], x='hypertension')\n",
    "sns.countplot(ax=axes[1,1], data=healthcare.df[stroke_false], x='hypertension')\n",
    "sns.countplot(ax=axes[2,0], data=healthcare.df[stroke_true], x='heart_disease')\n",
    "sns.countplot(ax=axes[2,1], data=healthcare.df[stroke_false], x='heart_disease')\n",
    "sns.countplot(ax=axes[3,0], data=healthcare.df[stroke_true], x='ever_married')\n",
    "sns.countplot(ax=axes[3,1], data=healthcare.df[stroke_false], x='ever_married')\n",
    "sns.countplot(ax=axes[4,0], data=healthcare.df[stroke_true], x='is_employed')\n",
    "sns.countplot(ax=axes[4,1], data=healthcare.df[stroke_false], x='is_employed')\n",
    "sns.countplot(ax=axes[5,0], data=healthcare.df[stroke_true], x='is_Rural')\n",
    "sns.countplot(ax=axes[5,1], data=healthcare.df[stroke_false], x='is_Rural')\n",
    "sns.countplot(ax=axes[6,0], data=healthcare.df[stroke_true], x='has_smoked')\n",
    "sns.countplot(ax=axes[6,1], data=healthcare.df[stroke_false], x='has_smoked')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06902a53-c6fe-4084-8b04-37b77a8b0d0a",
   "metadata": {},
   "source": [
    "Based on the results, we hypothesize that the features most relevant to predicting stroke are `is_employed`, `hypertension`, and `has_smoked`. \n",
    "\n",
    "We were surprised to learn that for patients who had a stroke, **all** of them were employed. It's important to note, though, that most of the patients from the dataset are employed. Additionally, `has_smoked` doesn't seem to matter as much as we thought. But we can conclude that there are more patients who smoke compared to those who don't for stroke cases, and vice versa for non-stroke cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2640aaac-12ad-4ce2-9187-08cb18872be6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Preparation (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc0aa10-2884-409b-a4f0-c27bb4b3aa06",
   "metadata": {},
   "source": [
    "To prep our data for machine learning, we called `__clean_df_2__()` from `DataPreparation` to convert all the quantitative variables to binary values. \n",
    "\n",
    "We converted \"age\" to `is_Old`, \"avg_glucose_level\" to `has_high_glucose`, and \"bmi\" to `is_Overweight`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d986761-d638-43ab-ad51-235afed55a48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# call 2nd class function\n",
    "healthcare.clean_df_2()\n",
    "healthcare.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fa7e9-ed9b-46f8-aa4b-07b9495dcacf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Comparing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a153b9f-fa53-4912-ae70-38dbb56291e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "We wanted to train two models and compare which of the two is better for predicting stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a18d70-f08a-4967-b528-ee6342f31cf6",
   "metadata": {},
   "source": [
    "To prep for that, we called `__train_test_split__()` from `DataPreparation` to split our data into train and test sets. That way, we can see how well each model performs on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2516530b-f7fe-45db-9192-95ad76056db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call 3rd class function\n",
    "X, y, X_train, X_test, y_train, y_test = healthcare.train_test_split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62da8f27-784f-4aa1-984e-6d0c3ca82064",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4b1ade-fee1-44f2-97b6-c6acf6c1dd1d",
   "metadata": {},
   "source": [
    "We fitted a Logistic Regression model on the training data and tested the model's performance on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca418f-e63f-4ed9-8215-d7af99bea5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bed052-2104-43dd-9f3e-993c1be105e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train logistic regression model\n",
    "m = LogisticRegression(solver=\"liblinear\")\n",
    "m.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7ff20-8bbd-4f10-80f3-8b8eca6ec957",
   "metadata": {},
   "source": [
    "Next, we computed the classification error for the training and test data to gauge the performance of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967dc1b0-75ce-4cc6-af9a-6ec8e609d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = m.score(X_train, y_train)\n",
    "test_score = m.score(X_test, y_test)\n",
    "print(\"train score: \", train_score)\n",
    "print(\"test score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78406cd0-2e0d-49fd-b026-e07751eb18a2",
   "metadata": {},
   "source": [
    "The train and test score are both high and close to 1, so our model is pretty good. However, these scores may not be accurate as they are dependent on the train-test split (random process). To account for the randomness, let's do a 3-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7494265-edf8-429b-a429-c5af51c0168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 3-fold cross validation score\n",
    "cv_score = cross_val_score(m, X_train, y_train, cv=3).mean()\n",
    "print(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb81d4-265d-49d8-810f-1e76df85e1cb",
   "metadata": {},
   "source": [
    "The 3-fold cross validation score is pretty high (nearly the same as the test score for one test-train split calculated previously) so we can conclude logistic regression is a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4aae9-0eb6-4883-9cb8-89cc043af2e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1a4c6-0045-4005-b59a-c7b991715953",
   "metadata": {},
   "source": [
    "But is there a better model? Let's train a Decision Tree Classifier model and compute cross-validation scores for max depth of 1-30. This will help us determine the depth that will give us the best Decision Tree Classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94d977-9de1-4446-9c21-ee7fd6a1cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6db7e5c-972f-44e2-9ca7-5cd5e28f13b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree(X, y, d):\n",
    "    '''\n",
    "    Args:\n",
    "        X: training data\n",
    "        y: testing data\n",
    "        d: depth\n",
    "    Returns:\n",
    "        T: instance of decisiontree classifier\n",
    "    '''\n",
    "    T = tree.DecisionTreeClassifier(max_depth=d) # create an instance of decisiontree classifier\n",
    "    T.fit(X, y) # train the decisiontree classifier model\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca31016-83ba-4810-95bd-feeb09ff7719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train data with decisiontree classifier\n",
    "fig, ax = plt.subplots(1, figsize= (10, 8))\n",
    "depths = range(1, 30)\n",
    "cv_scores = []\n",
    "\n",
    "T = tree.DecisionTreeClassifier(max_depth = 3)\n",
    "\n",
    "for d in depths:\n",
    "    T = fit_tree(X_train, y_train, d)\n",
    "    cv_score = cross_val_score(T, X_train, y_train, cv=3).mean() # compute 3-fold cv score\n",
    "    \n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "ax.scatter(depths, cv_scores, label='cv score')\n",
    "ax.set(xlabel=\"depth\", ylabel= 'score')\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "min_arg = np.argmax(cv_scores)\n",
    "\n",
    "print(\"best depth:\", depths[min_arg])\n",
    "print(\"highest CV score:\", cv_scores[min_arg])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4160a58-037f-43aa-b892-8825fa3dcb8b",
   "metadata": {},
   "source": [
    "Logistic Regression and Decision Tree Classifier (of any depth 1-5) are both good models for our dataset. The cross validation scores for Decision Tree Classifier were nearly the same for all depths (from 1-30). However, models with depths 1-5 perform slightly better than those with higher depths. Although Logistic Regression and Decision Tree Classifier are equally good models (both have a cross validation score of about 0.95), we will use the Logistic Regression model to examine which features are most correlated with getting a stroke."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790763a-a00c-45a4-8210-67b4deed5806",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e76143-5cca-4cfe-84f3-56ccb88761b2",
   "metadata": {},
   "source": [
    "Let's determine which features are the most relevant for predicting stroke using Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f3fbaf-9218-4c5b-8e3f-75d0174d50d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correlation Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a66df-9f07-41e9-932c-f2fb64b22f5b",
   "metadata": {},
   "source": [
    "We stored the names of all the features in a list called `column_names`, which we'll iterate through for our graph. We also calculated the correlation coefficients between each feature and `stroke`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb67acfe-8697-40fd-a039-01fcf3df3083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation coefficients\n",
    "m.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd249498-2abd-47d4-820d-23a7230ca9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of all the features\n",
    "column_names = list(X.columns.values)\n",
    "column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9924ef9e-1684-4057-84c8-40907e658a46",
   "metadata": {},
   "source": [
    "We created a graph that displays all the features and their corresponding correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1f70c5-b992-42b1-9009-6b01d7d87403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "plt.barh(column_names, m.coef_[0][:], 0.3) # plots features and coefficients\n",
    "plt.title(\"Logistic Regression Model\")\n",
    "plt.xlabel(\"Coefficients\")\n",
    "plt.axvline(x=0, color='gray') # creates line at 0 for x-axis\n",
    "plt.subplots_adjust(left=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5f8058-0109-4cb1-b068-5f79df89d089",
   "metadata": {},
   "source": [
    "The logistic regression coefficient **β** that is associated with each feature changes in log odds. This means that increasing the feature by 1 unit multiplies the chances of having the outcome by **eβ**. (https://quantifyinghealth.com/interpret-logistic-regression-coefficients/)\n",
    "\n",
    "To understand this better, we calculated the odds ratio for all the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7644c-dcb8-4d70-85c5-96f8da09b3bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Odds Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b69db-a14f-4170-a84d-751fd65ad0ce",
   "metadata": {},
   "source": [
    "Since we're working with medical data, let's interpret the coefficients as odds ratios to associate features to stroke risk. The odds ratio is the ratio of the probabilities of two mutually exclusive outcomes. For example, the odds of smoking group getting a stroke vs the odds of non-smoking group getting a stroke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682138b5-9f06-4ca7-bf8c-ff34314d95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265d4a67-a6bc-42c7-85e3-3d9f83e8789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list\n",
    "odds_ratio_L = []\n",
    "\n",
    "# compute odds ratio for each feature\n",
    "for i in m.coef_[0]:\n",
    "    odds_ratio = math.e**i\n",
    "    odds_ratio_L.append(odds_ratio) # add to list\n",
    "\n",
    "# save as numpy array\n",
    "odds_ratio_L = np.array(odds_ratio_L)\n",
    "print(\"odds ratio: \", odds_ratio_L)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
